{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in .\\venv\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in .\\venv\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in .\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in .\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in .\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in .\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in .\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in .\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in .\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in .\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in .\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in .\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in .\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in .\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n",
      "3.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf # type: ignore\n",
    "from tensorflow import keras # type:ignore\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf # type:ignore\n",
    "from tensorflow.keras.models import load_model\n",
    "import docx2txt\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned fake news detection model\n",
    "model = load_model('fake_news_detection_model.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure tokenizer settings (the same settings used during training)\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "max_length = 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(input_title, input_text):\n",
    "    combined_text = f\"{input_title} {input_text}\"\n",
    "    normalized_text = re.sub(r'https?://\\S+|www\\.\\S+', '', combined_text.lower())  # Remove URLs\n",
    "    normalized_text = re.sub(r'\\W', ' ', normalized_text)  # Remove non-word characters\n",
    "    normalized_text = re.sub(r'\\n', '', normalized_text)  # Remove newline characters\n",
    "    normalized_text = re.sub(r' +', ' ', normalized_text)  # Remove extra spaces\n",
    "    return normalized_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(model, tokenizer, input_title, input_text, max_length):\n",
    "    preprocessed_text = preprocess_input(input_title, input_text)\n",
    "    sequence = tokenizer.texts_to_sequences([preprocessed_text])\n",
    "    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, padding='post', maxlen=max_length)\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    return \"Real\" if prediction[0] >= 0.5 else \"Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_fake_news(title, text):\n",
    "    if not title or not text:\n",
    "        return \"Title and text cannot be empty.\"\n",
    "    print(f\"Title: {title}, Text: {text}\")  # Log inputs\n",
    "    result = predict_class(model, tokenizer, title, text, max_length)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import re\n",
    "from PyPDF2 import PdfReader  # Import for PDF handling\n",
    "import docx2txt  # Import for DOCX handling\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('D:\\\\final_year_project\\\\fake_news_detection_model.h5', compile=False)\n",
    "\n",
    "# Load the saved tokenizer\n",
    "with open('D:\\\\final_year_project\\\\tokenizer.pickle', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "max_length = 256\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_input(input_title, input_text):\n",
    "    combined_text = input_title + ' ' + input_text\n",
    "    normalized_text = re.sub('https?://\\S+|www\\.\\S+', '', combined_text.lower())\n",
    "    normalized_text = re.sub('\\\\W', ' ', normalized_text)\n",
    "    normalized_text = re.sub('\\n', '', normalized_text)\n",
    "    normalized_text = re.sub(' +', ' ', normalized_text)\n",
    "    return normalized_text.strip()\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(file):\n",
    "    reader = PdfReader(file)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to extract text from a DOCX file using docx2txt\n",
    "def extract_text_from_docx(file):\n",
    "    text = docx2txt.process(file)\n",
    "    return text\n",
    "\n",
    "# Function to extract text from uploaded file (PDF or DOCX)\n",
    "def extract_text_from_file(file):\n",
    "    if file.filename.endswith('.pdf'):\n",
    "        return extract_text_from_pdf(file)\n",
    "    elif file.filename.endswith('.docx'):\n",
    "        return extract_text_from_docx(file)\n",
    "    else:\n",
    "        return file.read().decode(\"utf-8\")  # Default to reading text if file is neither PDF nor DOCX\n",
    "\n",
    "# Prediction function\n",
    "def predict_class(model, tokenizer, input_title, input_text, max_length):\n",
    "    # Preprocess the input\n",
    "    preprocessed_text = preprocess_input(input_title, input_text)\n",
    "    \n",
    "    # Tokenize and pad the text\n",
    "    sequence = tokenizer.texts_to_sequences([preprocessed_text])\n",
    "    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, padding='post', maxlen=max_length)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    \n",
    "    # Return the result\n",
    "    return \"Real\" if prediction[0] >= 0.5 else \"Fake\"\n",
    "\n",
    "# Main function to detect fake news, with support for text or file input\n",
    "def detect_fake_news(input_title, input_text, file=None):\n",
    "    if file and file.filename: \n",
    "        input_text = extract_text_from_file(file)  \n",
    "        input_title = input_title or \"\"  \n",
    "\n",
    "    return predict_class(model, tokenizer, input_title, input_text, max_length)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
